{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "KeXLAJ89GYEz",
      "metadata": {
        "id": "KeXLAJ89GYEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1844d11c-119d-421c-80b7-3a72a729bf4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bm3d\n",
            "  Downloading bm3d-4.0.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting bm4d>=4.2.5 (from bm3d)\n",
            "  Downloading bm4d-4.2.5-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bm4d>=4.2.5->bm3d) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from bm4d>=4.2.5->bm3d) (1.13.1)\n",
            "Collecting PyWavelets (from bm4d>=4.2.5->bm3d)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading bm3d-4.0.3-py3-none-any.whl (10 kB)\n",
            "Downloading bm4d-4.2.5-py3-none-any.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.0/862.0 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, bm4d, bm3d\n",
            "Successfully installed PyWavelets-1.8.0 bm3d-4.0.3 bm4d-4.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install bm3d\n",
        "import bm3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e5f84c91-fb70-419e-b634-f4458b3278d8",
      "metadata": {
        "id": "e5f84c91-fb70-419e-b634-f4458b3278d8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cc983f99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc983f99",
        "outputId": "662180bb-bc43-41a5-b18d-9ac95e15e443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8ee14f77",
      "metadata": {
        "id": "8ee14f77"
      },
      "outputs": [],
      "source": [
        "# This function reduces salt-and-pepper noise from an image using a median filter.\n",
        "def reduceSaltAndPeperNoise(image, kernel=3):\n",
        "    image = np.array(image)\n",
        "\n",
        "    median_filtered = cv2.medianBlur(image, kernel)\n",
        "\n",
        "    # Convert the filtered image back to a PIL Image and return it\n",
        "    return Image.fromarray(median_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bd13b467",
      "metadata": {
        "id": "bd13b467"
      },
      "outputs": [],
      "source": [
        "# This function uses the BM3D algorithm to reduce Gaussian noise from an image.\n",
        "# Before using it, ensure the 'bm3d' package is installed by running: pip3 install bm3d\n",
        "def reduceGaussianNoise(image, sigma=20/255):\n",
        "    image     = np.array(image)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    R, G, B   = cv2.split(image_rgb)\n",
        "\n",
        "    # Apply BM3D denoising on each channel (R, G, B), normalize by 255.0 and scale back after denoising\n",
        "    R_denoised = bm3d.bm3d(R / 255.0, sigma) * 255\n",
        "    G_denoised = bm3d.bm3d(G / 255.0, sigma) * 255\n",
        "    B_denoised = bm3d.bm3d(B / 255.0, sigma) * 255\n",
        "\n",
        "    # Merge the denoised channels back into a single image\n",
        "    image_denoised = cv2.merge((R_denoised, G_denoised, B_denoised))\n",
        "    # Clip the values to be in the range [0, 255] and convert to uint8 type\n",
        "    image_denoised = np.clip(image_denoised, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Convert the image back to BGR color space before returning\n",
        "    image_denoised = cv2.cvtColor(image_denoised, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return image_denoised\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dd6ac2f8",
      "metadata": {
        "id": "dd6ac2f8"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file containing image labels\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/noise reduce/Labels.csv\")\n",
        "\n",
        "# Filter only the images with noise_type = \"Periodic\"\n",
        "periodic_images = df[df[\"noise_type\"] == \"Periodic\"][\"image_name\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5ad5c6c5",
      "metadata": {
        "id": "5ad5c6c5"
      },
      "outputs": [],
      "source": [
        "class DenoisingDatasetPeriodic(Dataset):\n",
        "    def __init__(self, noisy_dir, clean_dir, image_list, transform=None):\n",
        "        self.noisy_dir = noisy_dir\n",
        "        self.clean_dir = clean_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filter out invalid images\n",
        "        self.image_list = []\n",
        "        for filename in image_list:\n",
        "            noisy_path = os.path.join(self.noisy_dir, filename)\n",
        "            clean_path = os.path.join(self.clean_dir, filename)\n",
        "\n",
        "            if os.path.exists(noisy_path) and os.path.exists(clean_path):\n",
        "                noisy_img = cv2.imread(noisy_path)\n",
        "                clean_img = cv2.imread(clean_path)\n",
        "\n",
        "                if noisy_img is not None and clean_img is not None:\n",
        "                    self.image_list.append(filename)\n",
        "\n",
        "        print(f\"✅ Selected {len(self.image_list)} valid images out of {len(image_list)} total images.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.image_list[idx]\n",
        "        noisy_path = os.path.join(self.noisy_dir, filename)\n",
        "        clean_path = os.path.join(self.clean_dir, filename)\n",
        "\n",
        "        noisy_img = cv2.imread(noisy_path)\n",
        "        clean_img = cv2.imread(clean_path)\n",
        "\n",
        "        # Convert BGR to RGB\n",
        "        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)\n",
        "        clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Resize images\n",
        "        noisy_img = cv2.resize(noisy_img, (256, 256))\n",
        "        clean_img = cv2.resize(clean_img, (256, 256))\n",
        "\n",
        "        if self.transform:\n",
        "            noisy_img = self.transform(noisy_img)\n",
        "            clean_img = self.transform(clean_img)\n",
        "\n",
        "        return noisy_img, clean_img\n",
        "\n",
        "# 3. Image processing settings for RGB\n",
        "transformP = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "db639e40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db639e40",
        "outputId": "3684ea19-a03c-4812-fd72-e4b7fa73fb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Selected 477 valid images out of 479 total images.\n",
            "✅ Selected 54 valid images out of 54 total images.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Split dataset: 90% for training and 10% for testing\n",
        "random.shuffle(periodic_images)  # Shuffle the image list randomly\n",
        "train_size = int(0.9 * len(periodic_images))  # Compute training set size\n",
        "test_size  = len(periodic_images) - train_size  # Compute testing set size\n",
        "train_images, test_images = periodic_images[:train_size], periodic_images[train_size:]  # Split images\n",
        "\n",
        "# 4. Create training and testing datasets\n",
        "train_dataset = DenoisingDatasetPeriodic(\n",
        "    \"/content/drive/MyDrive/noise reduce/Noisy\",\n",
        "    \"/content/drive/MyDrive/noise reduce/Clean\",\n",
        "    train_images,\n",
        "    transform=transformP\n",
        ")\n",
        "\n",
        "test_dataset = DenoisingDatasetPeriodic(\n",
        "    \"/content/drive/MyDrive/noise reduce/Noisy\",\n",
        "    \"/content/drive/MyDrive/noise reduce/Clean\",\n",
        "    test_images,\n",
        "    transform=transformP\n",
        ")\n",
        "\n",
        "# Create DataLoaders for training and testing\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # Shuffle training data to improve generalization\n",
        "test_loader  = DataLoader(test_dataset, batch_size=4, shuffle=False)  # Keep test data order for consistent evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1b1055b2",
      "metadata": {
        "id": "1b1055b2"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Define the encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),  # First convolution layer for RGB input\n",
        "            nn.ReLU(),  # Activation function\n",
        "            nn.MaxPool2d(2, 2),  # Downsampling (reduces spatial size)\n",
        "            nn.Conv2d(64, 128, 3, padding=1),  # Second convolution layer\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, padding=1),  # Third convolution layer\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)  # Further downsampling\n",
        "        )\n",
        "\n",
        "        # Define the decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),  # First upsampling layer\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),  # Second upsampling layer\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 3, stride=2, padding=1, output_padding=1),  # Final layer to reconstruct RGB image\n",
        "            nn.Sigmoid()  # Output values scaled to [0,1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)  # Encode the input image\n",
        "        x = self.decoder(x)  # Decode to reconstruct the image\n",
        "        return x\n",
        "\n",
        "# Model testing\n",
        "encoder      = Autoencoder()\n",
        "sample_input = torch.randn(1, 3, 64, 64)  # A sample RGB image with size 64x64\n",
        "output       = encoder(sample_input)\n",
        "\n",
        "# 6. Model setup and training\n",
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, otherwise CPU\n",
        "encoder   = Autoencoder().to(device)  # Move model to the selected device\n",
        "criterion = nn.MSELoss()  # Mean Squared Error loss function for pixel-wise comparison\n",
        "optimizer = optim.Adam(encoder.parameters(), lr=0.0005)  # Adam(Adaptive Moment Estimation) optimizer with learning rate 0.0005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a8b9d613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8b9d613",
        "outputId": "eaf86208-bab6-4260-9698-9c2a9f9eecc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 0.4236\n",
            "Epoch [2/30], Loss: 0.3651\n",
            "Epoch [3/30], Loss: 0.1967\n",
            "Epoch [4/30], Loss: 0.4328\n",
            "Epoch [5/30], Loss: 0.3998\n",
            "Epoch [6/30], Loss: 0.1492\n",
            "Epoch [7/30], Loss: 0.0470\n",
            "Epoch [8/30], Loss: 0.7842\n",
            "Epoch [9/30], Loss: 0.4857\n",
            "Epoch [10/30], Loss: 0.3208\n",
            "Epoch [11/30], Loss: 0.2255\n",
            "Epoch [12/30], Loss: 0.5249\n",
            "Epoch [13/30], Loss: 0.2627\n",
            "Epoch [14/30], Loss: 0.7550\n",
            "Epoch [15/30], Loss: 0.5874\n",
            "Epoch [16/30], Loss: 0.4462\n",
            "Epoch [17/30], Loss: 0.4337\n",
            "Epoch [18/30], Loss: 0.2384\n",
            "Epoch [19/30], Loss: 0.7194\n",
            "Epoch [20/30], Loss: 0.6631\n",
            "Epoch [21/30], Loss: 0.1170\n",
            "Epoch [22/30], Loss: 0.4079\n",
            "Epoch [23/30], Loss: 0.3970\n",
            "Epoch [24/30], Loss: 0.6198\n",
            "Epoch [25/30], Loss: 0.4179\n",
            "Epoch [26/30], Loss: 0.6571\n",
            "Epoch [27/30], Loss: 0.5228\n",
            "Epoch [28/30], Loss: 0.4576\n",
            "Epoch [29/30], Loss: 0.0532\n",
            "Epoch [30/30], Loss: 0.1472\n"
          ]
        }
      ],
      "source": [
        "# 7. Train the model on the training dataset\n",
        "num_epochs = 30  # Number of epochs for training\n",
        "for epoch in range(num_epochs):\n",
        "    encoder.train()  # Set the model to training mode\n",
        "    for noisy_imgs, clean_imgs in train_loader:  # Iterate over training data\n",
        "        noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)  # Move data to the selected device (GPU/CPU)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients before the backward pass\n",
        "        outputs = encoder(noisy_imgs)  # Forward pass: get the model's predictions\n",
        "        loss = criterion(outputs, clean_imgs)  # Calculate the loss (MSE between predicted and true clean images)\n",
        "        loss.backward()  # Backward pass: compute gradients\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")  # Print loss after each epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3ff87b29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ff87b29",
        "outputId": "d5b5f470-5a86-4543-b829-dd0259f98af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3586\n"
          ]
        }
      ],
      "source": [
        "# 8. Evaluate the model on the test dataset\n",
        "encoder.eval()  # Set the model to evaluation mode (disables dropout, batch norm)\n",
        "total_loss = 0  # Initialize total loss for test dataset\n",
        "with torch.no_grad():  # Disable gradient computation (no need for backpropagation)\n",
        "    for noisy_imgs, clean_imgs in test_loader:  # Iterate over test data\n",
        "        noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)\n",
        "        outputs = encoder(noisy_imgs)  # Forward pass: get model's predictions\n",
        "        loss    = criterion(outputs, clean_imgs)  # Calculate the loss (MSE between predicted and true clean images)\n",
        "        total_loss += loss.item()  # Accumulate the loss\n",
        "\n",
        "# Calculate the average test loss over all batches\n",
        "avg_test_loss = total_loss / len(test_loader)\n",
        "print(f\"Test Loss: {avg_test_loss:.4f}\")  # Print the average test loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "742f617f",
      "metadata": {
        "id": "742f617f"
      },
      "outputs": [],
      "source": [
        "def reducePeriodicNoise(image, model, transform, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Apply the transformation (resize, normalization, etc.) and move it to the device (GPU/CPU)\n",
        "    noisy_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Disable gradient calculation (since we are not training the model)\n",
        "    with torch.no_grad():\n",
        "        denoised_tensor = model(noisy_tensor).cpu().squeeze(0)  # Get model output and move it to CPU\n",
        "\n",
        "    # Convert the model output (Tensor) to a NumPy array (from (Channels, Height, Width) to (H, W, C))\n",
        "    denoised_img = denoised_tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "    # Undo normalization and clip the values to [0, 255] for proper image representation\n",
        "    denoised_img = (denoised_img * 255).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "    return denoised_img  # Return the denoised image as a NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5c64c421",
      "metadata": {
        "id": "5c64c421"
      },
      "outputs": [],
      "source": [
        "# This function calculates the Peak Signal-to-Noise Ratio (PSNR) between the original and reconstructed images.\n",
        "def psnr(original_image, reconstructed_image):\n",
        "    original_image      = np.array(original_image, dtype=np.float64)\n",
        "    reconstructed_image = np.array(reconstructed_image, dtype=np.float64)\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE) between the original and reconstructed images\n",
        "    mse = np.mean((original_image - reconstructed_image) ** 2)\n",
        "\n",
        "    # If MSE is 0, return infinity (i.e., perfect match between images)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "\n",
        "    max_pixel_value = 255  # The maximum pixel value for an 8-bit image\n",
        "    # Calculate PSNR using the formula: PSNR = 10 * log10((max_value^2) / MSE)\n",
        "    psnr = 10 * np.log10((max_pixel_value ** 2) / mse)\n",
        "\n",
        "    return psnr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Pq2unNVfsggo",
      "metadata": {
        "id": "Pq2unNVfsggo"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "#open images and read images\n",
        "class NoiseDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.data       = pd.read_csv(csv_file)\n",
        "        self.img_dir    = img_dir\n",
        "        self.transform  = transform\n",
        "        self.label_map  = {\"Salt & Pepper\": 0, \"Gaussian\": 1, \"Periodic\": 2} #map noise type to number\n",
        "        self.valid_data = self._filter_valid_images()\n",
        "\n",
        "    def _filter_valid_images(self):\n",
        "        valid_rows = []\n",
        "        for idx in range(len(self.data)):\n",
        "            img_path = Path(self.img_dir) / self.data.iloc[idx, 0]\n",
        "            if img_path.exists():  # check for existing image\n",
        "                valid_rows.append(self.data.iloc[idx]) #append to dataset\n",
        "        return pd.DataFrame(valid_rows)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.valid_data.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        label = self.label_map[self.valid_data.iloc[idx, 1]]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "wX8__H70-uIr",
      "metadata": {
        "id": "wX8__H70-uIr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "148cdcd6-ea90-4495-af87-2e68c96dd7da"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'NoiseDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-96e4824991de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/noise reduce/Labels.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg_dir\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/noise reduce/Noisy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNoiseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# split data to train and test part with 0.8 rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NoiseDataset' is not defined"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 192)), #resize images for train model\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2), #cahnge brightness and contrast of images for better learning\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) #normalized images with static mean and std\n",
        "])\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/noise reduce/Labels.csv\"\n",
        "img_dir  = \"/content/drive/MyDrive/noise reduce/Noisy\"\n",
        "full_dataset = NoiseDataset(csv_path, img_dir, transform=transform)\n",
        "\n",
        "# split data to train and test part with 0.8 rate\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size  = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) #set batch size for train model\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False) #set natch size for test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "uDijK1fl_rx2",
      "metadata": {
        "id": "uDijK1fl_rx2"
      },
      "outputs": [],
      "source": [
        "#CNN definition for Lable Detection\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1) #concolutional layer definition\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool  = nn.MaxPool2d(2, 2) #compression features\n",
        "        self.fc1   = nn.Linear(64 * 32 * 24, 128) #reduce classes\n",
        "        self.fc2   = nn.Linear(128, 3) #reduce 128 classes to 3 classes\n",
        "        self.relu  = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x))) #layer 1 process\n",
        "        x = self.pool(self.relu(self.conv2(x))) #layer 2 process\n",
        "        x = self.pool(self.relu(self.conv3(x))) #layer 3 process\n",
        "\n",
        "        x = x.view(x.size(0), -1) #flatten images\n",
        "        x = self.relu(self.fc1(x)) #first layer\n",
        "        x = self.fc2(x) #end layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "byf7QDDQAPph",
      "metadata": {
        "id": "byf7QDDQAPph"
      },
      "outputs": [],
      "source": [
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #use GPU if we have GPU, else use CPU\n",
        "model     = CNNModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4) #set Adam optimizer and set learning rate to 0.0005 and set for weight_decay for reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "N2Qw1cvMC-8o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2Qw1cvMC-8o",
        "outputId": "39b4aed0-a084-45b9-8ed8-c2c2a9895578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.1020, Train Acc: 37.16%\n",
            "Epoch 2, Loss: 0.9037, Train Acc: 58.91%\n",
            "Epoch 3, Loss: 0.5764, Train Acc: 77.69%\n",
            "Epoch 4, Loss: 0.4281, Train Acc: 83.15%\n",
            "Epoch 5, Loss: 0.3297, Train Acc: 87.80%\n",
            "Epoch 6, Loss: 0.3774, Train Acc: 84.27%\n",
            "Epoch 7, Loss: 0.2916, Train Acc: 88.84%\n",
            "Epoch 8, Loss: 0.2888, Train Acc: 89.41%\n",
            "Epoch 9, Loss: 0.2602, Train Acc: 91.25%\n",
            "Epoch 10, Loss: 0.2299, Train Acc: 92.13%\n",
            "Epoch 11, Loss: 0.1867, Train Acc: 94.94%\n",
            "Epoch 12, Loss: 0.1854, Train Acc: 94.78%\n",
            "Epoch 13, Loss: 0.1874, Train Acc: 94.78%\n",
            "Epoch 14, Loss: 0.1858, Train Acc: 94.62%\n",
            "Epoch 15, Loss: 0.1787, Train Acc: 94.86%\n"
          ]
        }
      ],
      "source": [
        "#train model\n",
        "epochs    = 15\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) #Reduce the learning rate by a factor of ten every ten epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0 #total loss of each epoch\n",
        "    correct      = 0\n",
        "    total        = 0\n",
        "\n",
        "    for images, labels in train_loader: #load for all batches\n",
        "        images, labels = images.to(device), labels.to(device) #give every batch to devices(GPU)\n",
        "\n",
        "        optimizer.zero_grad() #set zero for all of last gradian\n",
        "        outputs = model(images) #provide the images to the model to obtain the output\n",
        "        loss = criterion(outputs, labels) #calcute loss value\n",
        "        loss.backward() #calcuteing the derivative of the error with respect to the weights\n",
        "        optimizer.step() #update weights\n",
        "\n",
        "        # calcute prediction\n",
        "        _, predicted = torch.max(outputs, 1) #find max of class\n",
        "        total += labels.size(0) #sum of visited items\n",
        "        correct += (predicted == labels).sum().item() #calcute sum of correct predicting\n",
        "\n",
        "        running_loss += loss.item() #reduce loarning rate\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    train_acc = 100 * correct / total #calcute accuracy\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8JmnWH1585zb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JmnWH1585zb",
        "outputId": "6ee3fc8c-426c-44d6-d904-ee103abf2d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n",
            "Precision: 0.94\n",
            "Recall: 0.94\n",
            "Specificity: 0.97\n",
            "F1-Score: 0.94\n",
            "Confusion Matrix:\n",
            "[[102   3   0]\n",
            " [ 15  82   0]\n",
            " [  0   1 109]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "model.eval() #set model to evaluation mode\n",
        "y_true = [] #real label\n",
        "y_pred = [] #model predict\n",
        "\n",
        "with torch.no_grad(): #stop cacuting gradian\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images) #model outputs for test datas\n",
        "        _, predicted = torch.max(outputs, 1) #find max classes\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy()) # transfer real labels from GPU to cpu and cascade them to numpy array\n",
        "        y_pred.extend(predicted.cpu().numpy()) # transfer predicted labels from GPU to cpu and cascade them to numpy array\n",
        "\n",
        "# calcuting Evaluation metrics\n",
        "accuracy    = accuracy_score  (y_true, y_pred)\n",
        "precision   = precision_score (y_true, y_pred, average=\"weighted\")\n",
        "recall      = recall_score    (y_true, y_pred, average=\"weighted\")\n",
        "f1          = f1_score        (y_true, y_pred, average=\"weighted\")\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "\n",
        "tn = conf_matrix[0][0]  # True Negative\n",
        "fp = conf_matrix[0][1]  # False Positive\n",
        "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # Preventing division by zero\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "UXNFmjuNeYs2",
      "metadata": {
        "id": "UXNFmjuNeYs2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1161fbae-7f8b-485e-f579-8135a76c262e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-017b5ed848a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#read images and convert them to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# send batch to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# پیش‌بینی مدل\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "# noisre classes\n",
        "class_labels = [\"Salt & Pepper\", \"Gaussian\", \"Periodic\"]\n",
        "\n",
        "image_folder       = \"/content/drive/MyDrive/noise reduce/Test\" # NoisyTest\n",
        "output_folder      = \"/content/drive/MyDrive/noise reduce/filtered_images\"\n",
        "clean_image_folder = \"/content/drive/MyDrive/noise reduce/Clean\" # Without-NoisyTest\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "psnr_values = []\n",
        "\n",
        "for img_name in os.listdir(image_folder):\n",
        "    img_path = os.path.join(image_folder, img_name)\n",
        "    image = Image.open(img_path).convert(\"RGB\") #read images and convert them to RGB\n",
        "    image_tensor = transform(image) #preprocess\n",
        "    image_tensor = image_tensor.unsqueeze(0).to(device)  # send batch to GPU\n",
        "\n",
        "    # پیش‌بینی مدل\n",
        "    with torch.no_grad():\n",
        "        output       = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)  # fing max class\n",
        "\n",
        "    predicted_label  = class_labels[predicted.item()]\n",
        "\n",
        "    #select function by label\n",
        "    if predicted_label == \"Salt & Pepper\":\n",
        "        filtered_image = reduceSaltAndPeperNoise(image)\n",
        "    elif predicted_label == \"Gaussian\":\n",
        "        filtered_image = reduceGaussianNoise(image)\n",
        "    elif predicted_label == \"Periodic\":\n",
        "        filtered_image = reducePeriodicNoise(image, encoder, transformP, device)\n",
        "\n",
        "    filtered_image = np.clip(filtered_image, 0, 255).astype(np.uint8)\n",
        "    image_pil = Image.fromarray(filtered_image)\n",
        "    output_path = os.path.join(output_folder, img_name)\n",
        "    image_pil.save(output_path)\n",
        "\n",
        "    original_path = os.path.join(clean_image_folder, img_name)\n",
        "    if os.path.exists(original_path):\n",
        "        original_image = Image.open(original_path).convert(\"RGB\")\n",
        "        psnr_value = psnr(original_image, filtered_image) #calcute PSNR\n",
        "        psnr_values.append(psnr_value)\n",
        "\n",
        "#calcute avg of PSNR\n",
        "if psnr_values:\n",
        "    mean_psnr = np.mean(psnr_values)\n",
        "    print(f\"میانگین PSNR برای تمام تصاویر: {mean_psnr:.2f} dB\")\n",
        "else:\n",
        "    print(\"هیچ مقدار PSNR محاسبه نشد!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3OnakUqSC3z"
      },
      "id": "o3OnakUqSC3z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "usr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}